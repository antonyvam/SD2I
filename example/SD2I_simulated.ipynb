{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robindong3/sd2i/blob/main/example/SD2I_simulated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiDk-lmrIU8P"
      },
      "source": [
        "Down load the miniconda and astra toolbox\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKoVW2zMKbP1",
        "outputId": "25066531-619c-498d-981f-f6b1374ce257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONPATH="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9z0yucyrIVbE"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-py39_23.3.1-0-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ua2A3EpHXge"
      },
      "outputs": [],
      "source": [
        "!conda --version\n",
        "!which conda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkS4q0LdMpXS"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "_ = (sys.path\n",
        "        .append(\"/usr/local/lib/python3.9/site-packages\"))\n",
        "sys.path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVg80N8t9VHh"
      },
      "outputs": [],
      "source": [
        "!conda install -c astra-toolbox/label/dev -y astra-toolbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tBY_qPxZmFP"
      },
      "outputs": [],
      "source": [
        "! pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/robindong3/sd2i.git"
      ],
      "metadata": {
        "id": "pCFcRsI0_F69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "! cd sd2i && pip install -e ."
      ],
      "metadata": {
        "id": "_Zj5QmMQeieH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! cd sd2i && pip install -e ."
      ],
      "metadata": {
        "id": "5vNLGCIwhqyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dhc9kliVM3WD"
      },
      "source": [
        "Import all packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQPMaKnBInjB"
      },
      "outputs": [],
      "source": [
        "from sd2i.shapes.phantoms import SheppLogan\n",
        "from sd2i.utils.plots import showim, cirmask\n",
        "from sd2i.utils.convtomo import fbpvol, sinocentering\n",
        "\n",
        "from sd2i.models.models_tf import GANrec, SD2I, Automap, Discriminator\n",
        "\n",
        "from sd2i.utils.utils_tf import ssim_mae_loss, discriminator_loss\n",
        "from sd2i.utils.utils_tf import tf_gpu_devices, ReduceLROnPlateau_custom\n",
        "from sd2i.utils.utils_tf import tf_create_angles, tf_tomo_transf, tf_tomo_radon, tf_tomo_squeeze, tf_tomo_bp, tf_mask_circle\n",
        "\n",
        "import tqdm as tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuUT2TDd9juu"
      },
      "source": [
        "Check if Tensorflow will run on GPU\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pIQgH2nMDb0"
      },
      "outputs": [],
      "source": [
        "tf_gpu_devices()\n",
        "\n",
        "physical_devices = tf.config.list_physical_devices('GPU') \n",
        "\n",
        "print(physical_devices)\n",
        "\n",
        "for device in physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFQrfZIn9lOq"
      },
      "source": [
        "Creating the image, sinogram, and mask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfbw4VBBZzvn"
      },
      "outputs": [],
      "source": [
        "npix = 128# image size\n",
        "npr = 128 # number of projections\n",
        "ang_samp = 4 # angular undersampling factor\n",
        "\n",
        "npr = npr // ang_samp\n",
        "\n",
        "with_disc = False # Use discriminator or not\n",
        "\n",
        "method = 'SD2Iup' # Choose method from 'SD2Iup', 'SD2I', 'GANrec', 'Automap'\n",
        "\n",
        "factor = 8 # Used for SD2I methods\n",
        "\n",
        "nim = 1\n",
        "\n",
        "im = SheppLogan(npix)\n",
        "\n",
        "#forward to create a comparable result, npix should be odd. one line/coloum of empty array are removed from edge \n",
        "odd_correction = False\n",
        "if npix % 2 == 0:\n",
        "    pad = np.zeros_like(im)\n",
        "    im = im[:-1,:-1]\n",
        "    npix -= 1\n",
        "    odd_correction = True\n",
        "\n",
        "showim(im, 1, cmap = 'jet')\n",
        "\n",
        "mask = np.ones((npix, npix))\n",
        "mask = cirmask(mask,0)\n",
        "\n",
        "mask = np.repeat(mask[:, :, np.newaxis], 1, axis=2)\n",
        "plt.imshow(mask[:,:,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSpT5F1T9pg9"
      },
      "source": [
        "Doing Radon transformation on the simulated image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQrE-ne0Z3XQ"
      },
      "outputs": [],
      "source": [
        "data = im.reshape([npix,npix,1])\n",
        "\n",
        "theta = tf_create_angles(npr)\n",
        "\n",
        "imtf = tf_tomo_transf(im)\n",
        "print(imtf.shape)\n",
        "\n",
        "pattern_input = tf_tomo_radon(imtf, theta, interp_method='bilinear')\n",
        "showim(tf_tomo_squeeze(pattern_input), 2)\n",
        "pattern_input = pattern_input[:,:,:,0]\n",
        "\n",
        "print(pattern_input.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdVyUbaj9ySF"
      },
      "source": [
        "Calculate the reconstructed image using the filtered back projection algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRjl3pH3Z6Yp"
      },
      "outputs": [],
      "source": [
        "fbp = fbpvol(np.array(pattern_input[0]).transpose(), theta=np.rad2deg(theta), nt = npix)\n",
        "showim(fbp, 3, clim=(0, np.max(fbp)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-KwSCVs90Ax"
      },
      "source": [
        "Next we prepare the function for training the neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRAJFly191tA"
      },
      "source": [
        "Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nIFvQIrZ8Iv"
      },
      "outputs": [],
      "source": [
        "if not with_disc:\n",
        "    @tf.function \n",
        "    def train_step(input_number, dataset):\n",
        "        print(1)\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "\n",
        "            generated_img = generator(input_number)\n",
        "          \n",
        "            print(generated_img.shape)\n",
        "\n",
        "            pattern_gen = tf_tomo_radon(generated_img, theta)\n",
        "            pattern_gen = pattern_gen[:,:,:,0]\n",
        "            pattern_gen = tf.transpose(pattern_gen, [1, 2, 0])\n",
        "            dataset = tf.transpose(dataset, [1, 2, 0])\n",
        "            print(3)\n",
        "            print(pattern_gen.shape)\n",
        "            print(dataset.shape)\n",
        "\n",
        "            matrix_loss = ssim_mae_loss(dataset, pattern_gen)\n",
        "\n",
        "        grad_gen = tape.gradient(matrix_loss, generator.trainable_variables)\n",
        "\n",
        "        gen_optimizer.apply_gradients(zip(grad_gen, generator.trainable_variables))\n",
        "        return matrix_loss\n",
        "\n",
        "else:\n",
        "    @tf.function \n",
        "    def train_step(input_number, dataset):\n",
        "        print(1)\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "\n",
        "            generated_img = generator(input_number)\n",
        "            generated_img = tf.math.abs(generated_img)\n",
        "            generated_img = generated_img[0,:,:,0] * mask[:,:,0]\n",
        "            generated_img = tf.reshape(generated_img, [1, generated_img.shape[0], generated_img.shape[1], 1])\n",
        "            print(generated_img.shape)\n",
        "\n",
        "            pattern_gen = tf_tomo_radon(generated_img, theta)\n",
        "            \n",
        "            real_output = discriminator(tf.expand_dims(dataset, -1))\n",
        "            generated_output = discriminator(pattern_gen)\n",
        "            \n",
        "            pattern_gen = pattern_gen[:,:,:,0]\n",
        "            pattern_gen = tf.transpose(pattern_gen, [1, 2, 0])\n",
        "            dataset = tf.transpose(dataset, [1, 2, 0])\n",
        "            print(2)\n",
        "            print(dataset.shape)\n",
        "            print(pattern_gen.shape)\n",
        "            gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=generated_output,\n",
        "                                      labels=tf.ones_like(generated_output))) \\\n",
        "                       + ssim_mae_loss(dataset, pattern_gen)\n",
        "\n",
        "            disc_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=real_output, labels=tf.ones_like(real_output)))\n",
        "            disc_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=generated_output, labels=tf.zeros_like(generated_output)))\n",
        "            disc_loss = disc_loss_real+disc_loss_fake\n",
        "\n",
        "        grad_disc = tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "        grad_gen = tape.gradient(gen_loss, generator.trainable_variables)\n",
        "\n",
        "        disc_optimizer.apply_gradients(zip(grad_disc, discriminator.trainable_variables))\n",
        "        gen_optimizer.apply_gradients(zip(grad_gen, generator.trainable_variables))\n",
        "        print(3)\n",
        "        return gen_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndexn3Bb94ns"
      },
      "source": [
        "Setup the model, optimizers and learning rate\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZtVAsKnaIQa"
      },
      "outputs": [],
      "source": [
        "if method == 'SD2Iup':\n",
        "    generator = SD2I(npix, factor)\n",
        "elif method == 'SD2I':\n",
        "    generator = SD2I(npix, factor, upsample=False)\n",
        "elif method == 'GANrec':\n",
        "    generator = GANrec(npix)\n",
        "elif method == 'Automap':\n",
        "    generator = Automap(npix, npr)\n",
        "    \n",
        "if with_disc:\n",
        "    discriminator = Discriminator(npix, npr)\n",
        "    disc_optimizer = tf.keras.optimizers.Adam(0.0005)\n",
        "    \n",
        "generator.summary()\n",
        "gen_optimizer = tf.keras.optimizers.Adam(0.005)\n",
        "\n",
        "reduce_rl_plateau = ReduceLROnPlateau_custom(patience=int(300/100),\n",
        "                            factor=0.5,\n",
        "                            verbose=1, \n",
        "                            optim_lr=gen_optimizer.learning_rate, \n",
        "                            reduce_lin=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyeRbvZj98cH"
      },
      "source": [
        "Setup the epochs needed and start the training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXkrs8JDaKYm"
      },
      "outputs": [],
      "source": [
        "epochs = 8000\n",
        "save_interval = 100\n",
        "\n",
        "chemct_tf = tf.cast(pattern_input, 'float32')\n",
        "\n",
        "if method == 'GANrec':\n",
        "    bp = tf_tomo_bp(chemct_tf, theta)\n",
        "    input_number = bp\n",
        "elif method == 'Automap':\n",
        "    input_number = chemct_tf\n",
        "else:\n",
        "    input_number = tf.cast(np.array([1]), 'float32')\n",
        "\n",
        "start = time.time()\n",
        "reduce_rl_plateau.on_train_begin()\n",
        "kk = 1\n",
        "\n",
        "for epoch in tqdm.tqdm_notebook(range(epochs)):\n",
        "\n",
        "    loss = train_step(input_number, chemct_tf)\n",
        "\n",
        "    if epoch % save_interval == 0 and epoch != 0:\n",
        "\n",
        "        print('Time for epoch {} to {} is {} sec/it - gen_loss = {}'.format(epoch - save_interval + 1, epoch, (time.time() - start) / save_interval, loss))\n",
        "        start = time.time()\n",
        "        plt.close()\n",
        "\n",
        "        reduce_rl_plateau.on_epoch_end(kk, loss)\n",
        "        kk += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxvKoptZ9_0m"
      },
      "source": [
        "Finally we plot the reconstructed image and compare it the filter back projected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8Xlz3y0dRfx"
      },
      "outputs": [],
      "source": [
        "generated_img = generator(input_number)\n",
        "generated_img = tf.math.abs(generated_img)\n",
        "generated_img = np.array(generated_img)\n",
        "generated_img[generated_img<0] = 0\n",
        "generated_img = generated_img[0,:,:,0] * mask[:,:,0]\n",
        "\n",
        "plt.figure(1, figsize=(14,14));plt.clf()\n",
        "plt.imshow(np.concatenate((im, fbp, generated_img[:,:]), axis=1), cmap='gray')\n",
        "plt.clim(0, 1)\n",
        "plt.title('Left: Ground Truth, Middle: FBP, Right: {}'.format(method))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_img = generator(input_number)\n",
        "generated_img = tf.math.abs(generated_img)\n",
        "generated_img = np.array(generated_img)"
      ],
      "metadata": {
        "id": "lQ1glZdEjfpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(generated_img)"
      ],
      "metadata": {
        "id": "a0en468ijhYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nC0fA9f9_K_"
      },
      "source": [
        "Do SIRT, SART, CGLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2ju5s4sfdXS"
      },
      "outputs": [],
      "source": [
        "img = [generated_img,  fbp, im]\n",
        "text = [str(method), 'FBP with angular_undersampling', 'ground truth']\n",
        "# %%\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from skimage.draw import random_shapes\n",
        "import astra\n",
        "from numpy import deg2rad, arange\n",
        "#%%\n",
        "def astra_rec_single(sino, theta=None, scanrange = '180', method='FBP_CUDA', filt='Ram-Lak', nits = None):\n",
        "    \n",
        "    '''\n",
        "    2D ct reconstruction using the astra-toolbox\n",
        "    1st dim in sinogram is translation steps, 2nd is projections\n",
        "    Available astra-toolbox reconstruction algorithms:\n",
        "    ART, SART, SIRT, CGLS, FBP\n",
        "    SIRT_CUDA, SART_CUDA, EM_CUDA, FBP_CUDA\n",
        "    \n",
        "    possible values for FilterType:\n",
        "    none, ram-lak, shepp-logan, cosine, hamming, hann, tukey, lanczos,\n",
        "    triangular, gaussian, barlett-hann, blackman, nuttall, blackman-harris,\n",
        "    blackman-nuttall, flat-top, kaiser, parzen    \n",
        "    '''\n",
        "    \n",
        "    npr = sino.shape[1] # Number of projections\n",
        "    \n",
        "    if theta is None:\n",
        "        if scanrange == '180':\n",
        "            theta = deg2rad(arange(0, 180, 180/npr))\n",
        "        elif scanrange == '360':\n",
        "            theta = deg2rad(arange(0, 360, 360/npr))\n",
        "            \n",
        "    # Create a basic square volume geometry\n",
        "    vol_geom = astra.create_vol_geom(sino.shape[0], sino.shape[0])\n",
        "    # Create a parallel beam geometry with 180 angles between 0 and pi, and image.shape[0] detector pixels of width 1.\n",
        "    proj_geom = astra.create_proj_geom('parallel', 1.0, int(1.0*sino.shape[0]), theta)\n",
        "    # Create a sinogram using the GPU.\n",
        "    proj_id = astra.create_projector('strip',proj_geom,vol_geom)\n",
        "    sinogram_id = astra.data2d.create('-sino', proj_geom, sino.transpose())\n",
        "    \n",
        "    # Create a data object for the reconstruction\n",
        "    rec_id = astra.data2d.create('-vol', vol_geom)\n",
        "    \n",
        "    cfg = astra.astra_dict(method)\n",
        "    cfg['ReconstructionDataId'] = rec_id\n",
        "    cfg['ProjectionDataId'] = sinogram_id\n",
        "    cfg['ProjectorId'] = proj_id\n",
        "    if method == 'FBP' or method == 'FBP_CUDA':\n",
        "        cfg['option'] = { 'FilterType': filt }\n",
        "    else:\n",
        "        if method == 'SART' or method == 'SIRT' or method == 'SART_CUDA' or method == 'SIRT_CUDA' or method == 'ART' or method == 'CGLS':\n",
        "            cfg['option']={}\n",
        "            cfg['option']['MinConstraint'] = 0\n",
        "        if nits is None:\n",
        "            nits = 10 \n",
        "    \n",
        "    # Create the algorithm object from the configuration structure\n",
        "    alg_id = astra.algorithm.create(cfg)\n",
        "\n",
        "    start=time.time()\n",
        "\n",
        "    if method == 'FBP' or method == 'FBP_CUDA':\n",
        "        rec = astra.algorithm.run(alg_id)\n",
        "    else:\n",
        "        rec = astra.algorithm.run(alg_id, nits)\n",
        "    \n",
        "    # Get the result\n",
        "    \n",
        "    rec = astra.data2d.get(rec_id)\n",
        "    \n",
        "    print((time.time()-start))\n",
        "        \n",
        "    astra.data2d.delete(sinogram_id)\n",
        "    astra.projector.delete(proj_id)\n",
        "    astra.algorithm.delete(alg_id)\n",
        "    astra.data2d.delete(rec_id)\n",
        "    \n",
        "    return(rec)\n",
        "# %%\n",
        "# %%\n",
        "\n",
        "method = ['SART_CUDA', 'CGLS_CUDA', 'SIRT_CUDA']\n",
        "\n",
        "for i in method:\n",
        "    rec = astra_rec_single(np.array(pattern_input[0,:,:]).transpose(), theta=None, scanrange = '180', method=i, filt='Ram-Lak', nits = 250)\n",
        "    rec[rec<0] = 0\n",
        "    img.append(rec)\n",
        "    text.append(i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQrCbeAQ-D5X"
      },
      "source": [
        "Finally calculate some metrics to compare the reconstructed images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP1QzoJ9qY3U"
      },
      "outputs": [],
      "source": [
        "if odd_correction:\n",
        "    full = np.zeros([npix+1, npix+1])\n",
        "    full[:-1,:-1] = im\n",
        "    full = tf.cast(full, tf.float32)\n",
        "else:\n",
        "    full = tf.cast(im, tf.float32)\n",
        "maxpoint = np.max(full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4eo5WL1fgN3"
      },
      "outputs": [],
      "source": [
        "print(full.shape)\n",
        "j = 0\n",
        "for i in img:\n",
        "    print(i.shape)\n",
        "    text_sub = text[j]\n",
        "    j += 1\n",
        "    im = np.reshape(i, (1, npix, npix,1))\n",
        "    gt = np.reshape(full, (1, full.shape[0],  full.shape[1],1))\n",
        "    \n",
        "    gt = tf.cast(gt, tf.float32)\n",
        "    if odd_correction:\n",
        "        im_new = np.zeros([1, npix+1, npix+1, 1])\n",
        "        im_new[:, :-1,:-1, :] = im\n",
        "        im = im_new\n",
        "        \n",
        "        i_new = np.zeros([npix+1, npix+1])\n",
        "        i_new[:-1,:-1] = i\n",
        "        i = i_new\n",
        "    \n",
        "    i = tf.cast(i, tf.float32)\n",
        "    im = tf.cast(im, tf.float32)\n",
        "    mae = tf.reduce_mean(tf.keras.losses.MAE(i, full)).numpy()\n",
        "\n",
        "    mse = tf.reduce_mean(tf.keras.losses.MSE(i, full)).numpy()\n",
        "\n",
        "    psnr = tf.image.psnr(im, gt, maxpoint).numpy()\n",
        "\n",
        "    ssim = tf.image.ssim(im, gt, maxpoint).numpy()\n",
        "    print(text_sub)\n",
        "    print('MAE: ', mae)\n",
        "    print('MSE: ', mse)\n",
        "    print('SSIM: ', ssim)\n",
        "    print('PSNR: ', psnr)\n",
        "    print('--------------------------------------')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z32x722rqWKi"
      },
      "outputs": [],
      "source": [
        "def plotfigs_imgs(imagelist, legendlist, rows=1, cols=5, figsize=(20,3), cl=True, cmap = 'gray'):\n",
        "    \n",
        "    '''\n",
        "    Create a collage of images without xticks/yticks\n",
        "    \n",
        "    @author: Antony Vamvakeros and Thanasis Giokaris\n",
        "    '''\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
        "        \n",
        "    kk = 0\n",
        "    for ii in range(axes.shape[0]):\n",
        "        for jj in range(axes.shape[1]):\n",
        "        \n",
        "            print(kk)\n",
        "            \n",
        "            if kk < len(imagelist):\n",
        "                # if kk != len(imagelist) - 1:\n",
        "                if 1 == 1:\n",
        "                    # imagelist[kk][imagelist[kk]>0.1] = 0.1\n",
        "                    # imagelist[kk][-1,-1] = 0.1\n",
        "                    \n",
        "                    # imagelist[kk][100:200,400:500][-1,-1] = maxpoint\n",
        "                    # imagelist[kk][-1,-1] = maxpoint\n",
        "                    # imagelist[kk][imagelist[kk]>40] = 40\n",
        "                    # i = axes[ii,jj].imshow(imagelist[kk][100:200,400:500], cmap=cmap,interpolation='none')\n",
        "                \n",
        "                    i = axes[ii,jj].imshow(imagelist[kk], cmap=cmap,interpolation='none')\n",
        "                    axes[ii,jj].set_axis_off()\n",
        "                    axes[ii,jj].set_title(legendlist[kk])\n",
        "                    # axes[ii,jj].clim(0,100)\n",
        "\n",
        "                    if cl==True:\n",
        "                        fig.colorbar(i, ax=axes[ii,jj])        \n",
        "                    \n",
        "                    kk = kk + 1\n",
        "                else:\n",
        "                    i = axes[ii,jj].imshow(imagelist[kk], cmap=cmap,interpolation='none')\n",
        "                    axes[ii,jj].set_axis_off()\n",
        "                    axes[ii,jj].set_title(legendlist[kk])\n",
        "                \n",
        "                    if cl==True:\n",
        "                        fig.colorbar(i, ax=axes[ii,jj])        \n",
        "                    \n",
        "\n",
        "                    kk = kk + 1\n",
        "    # fig.colorbar()\n",
        "#     fig.savefig(folder + 'XRDCT_ch{}.png'.format(ch)).\n",
        "plotfigs_imgs(img, text, rows=3, cols=2, figsize=(25,30), cl=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFE28yVTwfIp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}